% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gcor.R
\name{gcor}
\alias{gcor}
\title{Compute Generalized Partial Correlations for GLM terms}
\usage{
gcor(
  full_glm,
  terms = NULL,
  normalize = FALSE,
  intercept_too = FALSE,
  algorithm = "auto",
  algorithm.control = list(n_exact = 15, thresholds = c(-0.1, 0, 0.1), n_random = max(1,
    13 + log(1/nrow(model.matrix(full_glm)))), max_iter = 1000, topK = max(10, min(100,
    length(nrow(model.matrix(full_glm)))/10)), tol = 1e-12, patience = 10)
)
}
\arguments{
\item{full_glm}{A fitted GLM object of class `glm`.}

\item{terms}{Character vector of variable names (referred to the
model.matrix, that is pay attention for factors) for which to compute
generalized partial correlations. If `NULL` (default), computes for all
non-intercept terms in the model.}

\item{normalize}{FALSE by default.}

\item{intercept_too}{Logical indicating whether to include the intercept
as a variable. Default is FALSE.}

\item{algorithm.control}{Only used if \code{normalize} is \code{TRUE}. `list` of control parameters:
`n_exact` Integer specifying the sample size threshold for using exact
  methods (brute force). Default is 15.
`thresholds` Numeric vector of threshold values for multi-start initialization.
`n_random` Integer number of random starts for multi-start optimization.
`max_iter` Integer maximum number of iterations per start.
`topK` Integer number of top candidates to consider at each iteration.
`tol` Numeric tolerance for convergence.
`patience` Integer number of iterations without improvement before stopping.}

\item{algorith}{Only used if \code{normalize} is \code{TRUE}. `"auto"` by default. It choose between `"intercept_only"`, `"brute_force"` and `"multi_start"`}
}
\value{
if \code{normalize} is \code{FALSE}, a data frame with five columns:
  \item{variable}{The variable name}
  \item{r}{The generalized partial correlation coefficient}
  while if \code{normalize} is \code{TRUE}
  \item{terms}{The variable name}
  \item{r}{The generalized partial correlation coefficient}
  \item{r_n}{The normalized generalized partial correlation coefficient}
  \item{null_model}{The null model used to compute the generalized (partial) correlation}
  \item{algorithm}{The algorithm used to compute the upper/lower bounds of the generalized partial correlation coefficient (to compute its normalized version)}
  \item{exact}{logical}
}
\description{
This function computes the generalized partial correlation coefficient \eqn{r}
for each specified variable in a generalized linear model. For each variable,
it refits the null model excluding that variable and computes the cosine similarity
between the residualized predictor and standardized residuals.
}
\details{
The generalized partial correlation \eqn{\r} measures the association between
a predictor and response after adjusting for all other terms in the model.
It is defined as the cosine similarity between the residualized predictor
\eqn{X_r} and standardized residuals \eqn{Y_r}:

\deqn{\r = \frac{X_r^\top Y_r}{\|X_r\| \|Y_r\|}}

where:
\itemize{
  \item \eqn{X_r = (I - H)W^{1/2}X} is the residualized predictor
  \item \eqn{Y_r = V^{-1/2}(Y - \hat{\mu})} is the standardized residual vector
  \item \eqn{H} is the hat matrix for the nuisance covariates
  \item \eqn{W = DV^{-1}D} is the weight matrix
  \item \eqn{V} is the variance matrix and \eqn{D} is the derivative matrix
}

The function uses `flipscores:::get_par_expo_fam()` to compute \eqn{V} and \eqn{D}
consistently with the flipscores package methodology.

The normalized generalized partial correlation is computed as:
\deqn{
r_n = \begin{cases}
+r / r_+ & \text{if } r > 0 \\
-r / r_- & \text{if } r < 0
\end{cases}
}
where \eqn{r_+} is the maximum possible correlation and \eqn{r_-} is the minimum.

When the (full) model has only intercept and only one predictor X, the
generalized (non partial) correlation is computed and the normalization factor
for X is exact.
In the more general case with more predictors, for sample sizes \eqn{n \leq n_{\text{exact}}}, brute force search is used to find
the exact extrema. For larger sample sizes, a greedy multi-start algorithm is employed:
\itemize{
  \item Multiple starting points are generated using thresholding and random sampling
  \item From each start, coordinates are greedily flipped to improve the correlation
  \item Early stopping is used when no improvements are found for several iterations
  \item The best solution across all starts is returned
}
This approach provides a good trade-off between computational efficiency and solution
quality for large problems where brute force is infeasible.
}
\examples{
set.seed(1)
dt=data.frame(X=rnorm(20),
   Z=factor(rep(LETTERS[1:3],length.out=20)))
dt$Y=rpois(n=20,lambda=exp(dt$Z=="C"))
mod=flipscores(Y~Z+X,data=dt,family="poisson",n_flips=1000)
summary(mod)

# Compute generalized partial correlations for all terms
(results <- gcor(mod))

# Compute for specific terms only
gcor(mod, terms = c("X", "ZC"))

gcor(mod, terms = c("X", "ZC"),normalize=TRUE)


gcor(mod, intercept_too=TRUE, normalize=TRUE)
set.seed(123)
dt=data.frame(X=rnorm(20),
   Z=factor(rep(LETTERS[1:3],length.out=20)))
dt$Y=rbinom(n=20,prob=plogis((dt$Z=="C")*2),size=1)
mod=flipscores(Y~Z+X,data=dt,family="binomial",n_flips=1000)
summary(mod)

(results <- gcor(mod,normalize=TRUE))
# Compute for specific terms only
gcor(mod, terms = c("X", "ZC"),normalize=TRUE)


}
\author{
Livio Finos and Paolo Girardi
}
